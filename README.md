# airflow
 Help to manage multiple Data pipelines
benefits 1 everything in python and dynamic ,2.scalblity 3. user interface 4.Extensibilty -you can add multiple plugins you needed 
components 
1.web server - flux python web server that allows you to the use interface  
2.scheduler  - shedule your tasks and your data pipeline 
3.Metastore  - Data base compatable with the sequal like postgres,mysql,oracle-db contain metadata related to the pipelines and the task 
4.Triggere - Allows you to run specific kind of Task .
5.Executor - Defines How and on which pod your task is execuated 
Queue - your task push in it to executed in an order.
Worker - where your task are effectively executed .
****
DAG -- Directe asicallty Graph
Operator - It is nothing but like the task 
1. Action operator-
2. Transfer operator-
3. Sensor operator -
4.
5.
